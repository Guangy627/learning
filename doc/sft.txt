sft精髓：

什么时候用到 -- 当你的prompt engineering 逼近极限
通用对齐人类任务   -- 一般我会选用instruct做为基座 
                -- instruct已经学会了遵循指令，我只需要在数据领域熵补充任务数据和风格，避免了数据浪费和数据遗忘


数据部分：

pre-requirement:
少量数据评估本次sft是否有意义，还可以尝试以部分数据为seed来寻找scaling law （是增加模型大小还是增加数据量）, 如果没有收益请检查数据集的质量
可混入一部分的预置数据（15%-30%），保持模型基本通用能力，比例就要看任务本身要求了。我是觉得一些specific的任务我只用保持模型的文字连续性就行，足够输出。

冷启动数据准备很重要 -- 个人认为决定了模型的上限，分布不稳定，覆盖不全，指令风格不一致， 模型学到的东西就会broken，之后再进行优化也只会放大噪声


我常用的sft -- 
1.lora --可以选择finetune很多不同的layer 注意力层（Q,K,V,O),feed-forward(W_in, W_out)

2.qlora
